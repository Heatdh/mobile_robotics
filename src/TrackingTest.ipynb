{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564dd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import atan2, cos, sin, sqrt, pi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572c02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7febf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertWheelSpeeds(speed_l,speed_r,speed_factor=3,axle_track=94):\n",
    "    '''\n",
    "    Function that takes the raw values of each motor angular speed and converts it into\n",
    "    translation speed (in mm/s) and rotation speed (rad/sec) with a pixel scaling factor.\n",
    "\n",
    "    Inputs: - speed_l: speed of left motor (no units, from Thymio measurements)\n",
    "            - speed_r: speed of right motor (no units, from Thymio measurements)\n",
    "            - speed_factor: 3 (motor_target of 200 sent to Thymio corresponds to a wheel speed of 66.8 mm/s)\n",
    "            - axle_track: 94mm (distance between both wheels)\n",
    "\n",
    "    Output: - v  : The current forward velocity of the Thymio (in mm/s)\n",
    "            - omega : The current angular velocity of the Thymio (in rad/s)(positive direction corresponding to that of the camera frame)\n",
    "    '''\n",
    "    # wheel_radius : 22mm\n",
    "    # axle track : 94mm (distance between the 2 wheels)\n",
    "    v = 0.5*(speed_l + speed_r) / speed_factor\n",
    "    omega = (speed_l - speed_r) / (0.5*axle_track*speed_factor)\n",
    "    \n",
    "    return v, omega\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a87bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9c0ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def px2real(x_px, scalingFactor):\n",
    "    '''\n",
    "    Function that converts measurement in pixels to measurement in mm.\n",
    "\n",
    "    Inputs: - x_px : value in pixels\n",
    "            - scalingFactor : for image size (1920x1080) corresponding to real length and width (800mm x 450mm), the scalingFactor is 2.4 \n",
    "\n",
    "    Output: - x_real : value in mm\n",
    "            \n",
    "    '''\n",
    "    x_real = x_px / 2.4\n",
    "    return x_real\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b75920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real2px(x_real, scalingFactor):\n",
    "    '''\n",
    "    Function that converts measurement in mm to measurement in pixels.\n",
    "\n",
    "    Inputs: - x_real : value in mm\n",
    "            - scalingFactor : for image size (1920x1080) corresponding to real length and width (800mm x 450mm), the scalingFactor is 2.4 \n",
    "\n",
    "    Output: - x_px : value in pixels\n",
    "            \n",
    "    '''\n",
    "    x_px = x_real * 2.4\n",
    "    return x_px\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1b4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extended Kalman Filter class\n",
    "\n",
    "Code modified from https://github.com/L42Project/Tutoriels/blob/master/Divers/tutoriel36/KalmanFilter.py\n",
    "Comments describing Kalman Filter taken from https://stackoverflow.com/questions/74318200/how-to-tune-extended-kalman-filter-on-pykalman\n",
    "\n",
    "Example of instance: KF=KalmanFilter(0.03333, [0, 0, 0, 0, 0]) (dt = 0.033 is the time between each measurement, x_ini = [0, 0, 0, 0, 0] is the initial state)\n",
    "\n",
    "For update() function : takes as input the measurement vector z\n",
    "z[0:2] are the measurements from the camera (px, py, orientation)\n",
    "z[3:4] are the measurements from the Thymio (forward speed v and angular speed omega)\n",
    "\n",
    "When Thymio position not found by camera -> z becomes 2x1 vector, with z[0:1] being the forward speed v and angular speed omega\n",
    "'''\n",
    "\n",
    "\n",
    "class KalmanFilter():\n",
    "    def __init__(self, dt, x_ini):\n",
    "        self.dt = dt\n",
    "\n",
    "        # Initial State Vector\n",
    "        self.x=np.matrix([[x_ini[0]], [x_ini[1]], [x_ini[2]], [x_ini[3]], [x_ini[4]]])\n",
    "    \n",
    "\n",
    "        # Initialize State Transition Matrix (Warning : changes with time -> updateFk())\n",
    "        self.Fk=np.eye(5)\n",
    "\n",
    "        # Initialize Measurement matrix H\n",
    "        # Used to convert the predicted state estimate into predicted sensor measurements at time k.\n",
    "        # In this case, H will be the identity matrix since the estimated state maps directly to state measurements data\n",
    "        # H has the same number of rows as sensor measurements and same number of columns as states.\n",
    "        self.H=np.eye(5)\n",
    "\n",
    "        \n",
    "        # State model noise covariance matrix Q\n",
    "        # When Q is large, the Kalman Filter tracks large changes in\n",
    "        # the sensor measurements more closely than for smaller Q.\n",
    "        # Q is a square matrix that has the same number of rows as states.\n",
    "        self.Q=np.diag([1, 0.1, 0.01, 1.0, 1.0]) \n",
    "        \n",
    "\n",
    "        # Sensor measurement noise covariance matrix R\n",
    "        # Has the same number of rows and columns as sensor measurements.\n",
    "        # If we are sure about the measurements, R will be near zero.\n",
    "        self.coord_var = 0.01\n",
    "        self.angle_var = 0.0001\n",
    "        self.speed_var = 6.0\n",
    "        self.omega_var = 0\n",
    "        \n",
    "        self.R=np.diag([self.coord_var, self.coord_var, self.angle_var, self.speed_var, self.omega_var])\n",
    "\n",
    "        self.P=np.eye(5)\n",
    "        \n",
    "    def updateFk(self):\n",
    "        '''\n",
    "        Function that updates the state transition matrix Fk\n",
    "        '''\n",
    "        \n",
    "        self.Fk=np.matrix([[1.0, 0, 0, self.dt*math.cos(self.x[2]), 0],\n",
    "                           [0, 1.0,  0, self.dt*math.sin(self.x[2]), 0],\n",
    "                           [0, 0, 1.0, 0, self.dt],\n",
    "                           [0, 0, 0, 1.0, 0],\n",
    "                           [0, 0, 0, 0, 1.0]])\n",
    "        self.Fk = self.Fk.astype(float)\n",
    "\n",
    "    def predict(self):\n",
    "        # Update Fk\n",
    "        self.updateFk()\n",
    "        # Predict the state estimate (A Priori) at time k based on the state estimate at time k-1\n",
    "        self.x=np.dot(self.Fk, self.x)\n",
    "        # Predict the state covariance estimate based on the previous covariance and some noise\n",
    "        self.P=np.dot(np.dot(self.Fk, self.P), self.Fk.T)+self.Q\n",
    "        return self.x\n",
    "\n",
    "    def update(self, z, CameraAccessible = True): # z[0:2] corrpesonds to measurement of camera, z[3:4] corresponds to measurements of wheels\n",
    "        \n",
    "        if CameraAccessible:\n",
    "            self.H=np.eye(5)\n",
    "            \n",
    "            self.R=np.diag([self.coord_var, self.coord_var, self.angle_var, self.speed_var, self.omega_var])\n",
    "        else: # CAUTION : IF CAMERAACCESSIBLE = FALSE, Z IS A 2x1 VECTOR (z[0:1] are now measrurements from wheels)\n",
    "            # Measurement matrix H (now only v and omega can be observed)\n",
    "            self.H=np.matrix([[0, 0, 0, 1, 0],\n",
    "                              [0, 0, 0, 0, 1]])\n",
    "            \n",
    "            self.R=np.diag([self.speed_var, self.omega_var])\n",
    "            \n",
    "            \n",
    "        # Compute Kalman gain\n",
    "        S=np.dot(self.H, np.dot(self.P, self.H.T))+self.R\n",
    "        inv_S = np.linalg.pinv(S.astype(float))\n",
    "        K=np.dot(np.dot(self.P, self.H.T),inv_S)\n",
    "\n",
    "        # Correction / innovation\n",
    "        # Calculate an updated state estimate (A Posteriori) for time k\n",
    "        self.x=self.x+np.dot(K, (z-np.dot(self.H, self.x)))\n",
    "        # Update the state covariance estimate for time k\n",
    "        I=np.eye(self.H.shape[1])\n",
    "        self.P=(I-(K*self.H))*self.P\n",
    "\n",
    "\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fc08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d25434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(pt1, pt2):\n",
    "    distance = ( (pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2 )**0.5\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd9c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thymio_position(img, img_output):\n",
    "    \n",
    "    '''\n",
    "    Function that outputs Thymio position, radius and orientation from camera frames using Aruco marker detection\n",
    "    Parts of code taken from https://mecaruco2.readthedocs.io/en/latest/notebooks_rst/Aruco/aruco_basics.html\n",
    "\n",
    "    Inputs: - img : image from camera in BGR format\n",
    "            - img_output : copy of image img on which will be drawn Thymio's contours\n",
    "\n",
    "    Output: - center : tuple (x,y) representing the center of the Thymio (in pixels)\n",
    "            - radius : radius of the Thymio (in pixels)\n",
    "            - angle : orientation of the Thymio (in radians)\n",
    "            - thymio_detected : boolean set to True if Thymio was detected, False if not\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "    parameters =  aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    frame_markers = aruco.drawDetectedMarkers(img_output, corners, ids)\n",
    "    \n",
    "    \n",
    "    thymio_detected = False\n",
    "    center = (0,0)\n",
    "    radius = 0\n",
    "    angle = 0\n",
    "    \n",
    "    if np.all(ids != None):\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] == 0:\n",
    "                thymio_detected = True\n",
    "                c = corners[i][0]\n",
    "\n",
    "                top_center = (c[0:2, 0].mean(),c[0:2, 1].mean())\n",
    "                bottom_center = (c[2:4, 0].mean(), c[2:4, 1].mean())\n",
    "                left_center = (c[0:4:3, 0].mean(), c[0:4:3, 1].mean())\n",
    "                right_center = (c[1:3, 0].mean(), c[1:3, 1].mean())\n",
    "                points = np.array([ [c[2,0],c[2,1]], [c[3,0],c[3,1]], [left_center[0],left_center[1]], [right_center[0],right_center[1]] ])\n",
    "\n",
    "                square_center = (int(c[:, 0].mean()), int(c[:, 1].mean()))\n",
    "                radius = int(max( dist(square_center,c[0]), dist(square_center,c[1]), dist(square_center,c[2]), dist(square_center,c[3])))\n",
    "                angle = math.atan2(top_center[1]-bottom_center[1],top_center[0]-bottom_center[0])\n",
    "                \n",
    "                \n",
    "                center = (int(points[:, 0].mean()), int(points[:, 1].mean()))\n",
    "                cv2.arrowedLine(img_output, (center[0],center[1]), (int(top_center[0]),int(top_center[1])), (255,255,0), 10)\n",
    "                cv2.circle(img_output,square_center,radius,(255,0,0),10)\n",
    "\n",
    "                break\n",
    "\n",
    "        \n",
    "    return center, radius, angle, thymio_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c069c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1d540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     41\u001b[0m imgResult \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 43\u001b[0m thymioLoc, thymioRadius, thymioAngle, thymioDetected \u001b[38;5;241m=\u001b[39m \u001b[43mget_thymio_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgResult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# KALMAN -------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     46\u001b[0m KF\u001b[38;5;241m.\u001b[39mpredict()\n",
      "Cell \u001b[1;32mIn [7], line 20\u001b[0m, in \u001b[0;36mget_thymio_position\u001b[1;34m(img, img_output)\u001b[0m\n\u001b[0;32m     18\u001b[0m aruco_dict \u001b[38;5;241m=\u001b[39m aruco\u001b[38;5;241m.\u001b[39mDictionary_get(cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mDICT_4X4_50)\n\u001b[0;32m     19\u001b[0m parameters \u001b[38;5;241m=\u001b[39m  aruco\u001b[38;5;241m.\u001b[39mDetectorParameters_create()\n\u001b[1;32m---> 20\u001b[0m corners, ids, rejectedImgPoints \u001b[38;5;241m=\u001b[39m \u001b[43maruco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMarkers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maruco_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m frame_markers \u001b[38;5;241m=\u001b[39m aruco\u001b[38;5;241m.\u001b[39mdrawDetectedMarkers(img_output, corners, ids)\n\u001b[0;32m     24\u001b[0m thymio_detected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing Kalman Filter\n",
    "'''\n",
    "\n",
    "global center, radius, angle, thymio_detected\n",
    "\n",
    "forward_speed = 0\n",
    "angular_speed = 0\n",
    "\n",
    "KF=KalmanFilter(0.033, [500, 300, math.pi/4, forward_speed, angular_speed])\n",
    "\n",
    "\n",
    "\n",
    "### INITIALIZE CAMERA\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "fps = int(cap.get(5))\n",
    "print(\"fps:\", fps)\n",
    "\n",
    "success, img = cap.read()\n",
    "imgResult = img.copy()\n",
    "    \n",
    "thymioLoc, thymioRadius, thymioAngle, thymioDetected = get_thymio_position(img, imgResult)\n",
    "\n",
    "\n",
    "path = [[thymioLoc[0],thymioLoc[1]],[thymioLoc[0]+300,thymioLoc[1]+300],[thymioLoc[0]+500,thymioLoc[1]-300]]\n",
    "\n",
    "### MAIN LOOP\n",
    "count = 0\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    \n",
    "# running infinite while loop so that\n",
    "# program keep running until we close it\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgResult = img.copy()\n",
    "    \n",
    "    thymioLoc, thymioRadius, thymioAngle, thymioDetected = get_thymio_position(img, imgResult)\n",
    "    \n",
    "    # KALMAN -------------------------------------------------------------------\n",
    "    KF.predict()\n",
    "    if thymioDetected:\n",
    "        z = np.array([thymioLoc[0],thymioLoc[1],thymioAngle, forward_speed, angular_speed])\n",
    "        z = np.expand_dims(z, axis=-1)\n",
    "    else:\n",
    "        z = np.array([forward_speed, angular_speed]) \n",
    "        z = np.expand_dims(z, axis=-1)\n",
    "    KF.update(z,thymioDetected)\n",
    "    cv2.circle(imgResult, (int(KF.x[0]), int(KF.x[1])), 10, (255,0,255), 10)\n",
    "    # KALMAN ----------------------------------------------------------------------\n",
    "    count = count + 1\n",
    "    #print(count)\n",
    "    #print('Thymio center:',thymioLoc, '  Angle:',thymioAngle, '  Thymio Detected:' ,thymioDetected)\n",
    "    #print('Kalman center:',KF.x[0:2],'  Kalman angle:',KF.x[2], 'Kalman speed and omega', KF.x[3:5])\n",
    "    \n",
    "    #Path tracking ----------------------------------------------------------------\n",
    "    x = KF.x[0]\n",
    "    y = KF.x[1]\n",
    "    angle = KF.x[2]\n",
    "\n",
    "    # displaying output on Screen\n",
    "    imgResult = cv2.line(imgResult,tuple(path[0]),tuple(path[1]),(255,255,255),1)\n",
    "    imgResult = cv2.line(imgResult,tuple(path[1]),tuple(path[2]),(255,255,255),1)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349851e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7946f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d1a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

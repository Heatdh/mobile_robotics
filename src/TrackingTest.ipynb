{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f99192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564dd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from math import atan2, cos, sin, sqrt, pi\n",
    "import numpy as np\n",
    "from sympy import Segment, Point, Ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7552f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_var(motor_left_target = 60)\n",
    "set_var(motor_right_target = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85428b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_var(motor_left_target = 0)\n",
    "set_var(motor_right_target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7febf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertWheelSpeeds(speed_l,speed_r,speed_factor=3,axle_track=94):\n",
    "    '''\n",
    "    Function that takes the raw values of each motor angular speed and converts it into\n",
    "    translation speed (in mm/s) and rotation speed (rad/sec) with a pixel scaling factor.\n",
    "\n",
    "    Inputs: - speed_l: speed of left motor (no units, from Thymio measurements)\n",
    "            - speed_r: speed of right motor (no units, from Thymio measurements)\n",
    "            - speed_factor: 3 (motor_target of 200 sent to Thymio corresponds to a wheel speed of 66.8 mm/s)\n",
    "            - axle_track: 94mm (distance between both wheels)\n",
    "\n",
    "    Output: - v  : The current forward velocity of the Thymio (in mm/s)\n",
    "            - omega : The current angular velocity of the Thymio (in rad/s)(positive direction corresponding to that of the camera frame)\n",
    "    '''\n",
    "    # wheel_radius : 22mm\n",
    "    # axle track : 94mm (distance between the 2 wheels)\n",
    "    v = 0.5*(speed_l + speed_r) / speed_factor\n",
    "    omega = (speed_l - speed_r) / (0.5*axle_track*speed_factor)\n",
    "    \n",
    "    return v, omega\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a87bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c0ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def px2real(x_px, scalingFactor):\n",
    "    '''\n",
    "    Function that converts measurement in pixels to measurement in mm.\n",
    "\n",
    "    Inputs: - x_px : value in pixels\n",
    "            - scalingFactor : for image size (1920x1080) corresponding to real length and width (800mm x 450mm), the scalingFactor is 2.4 \n",
    "\n",
    "    Output: - x_real : value in mm\n",
    "            \n",
    "    '''\n",
    "    x_real = x_px / 2.4\n",
    "    return x_real\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b75920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real2px(x_real, scalingFactor):\n",
    "    '''\n",
    "    Function that converts measurement in mm to measurement in pixels.\n",
    "\n",
    "    Inputs: - x_real : value in mm\n",
    "            - scalingFactor : for image size (1920x1080) corresponding to real length and width (800mm x 450mm), the scalingFactor is 2.4 \n",
    "\n",
    "    Output: - x_px : value in pixels\n",
    "            \n",
    "    '''\n",
    "    x_px = x_real * 2.4\n",
    "    return x_px\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b1b4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extended Kalman Filter class\n",
    "\n",
    "Code modified from https://github.com/L42Project/Tutoriels/blob/master/Divers/tutoriel36/KalmanFilter.py\n",
    "Comments describing Kalman Filter taken from https://stackoverflow.com/questions/74318200/how-to-tune-extended-kalman-filter-on-pykalman\n",
    "\n",
    "Example of instance: KF=KalmanFilter(0.03333, [0, 0, 0, 0, 0]) (dt = 0.033 is the time between each measurement, x_ini = [0, 0, 0, 0, 0] is the initial state)\n",
    "\n",
    "For update() function : takes as input the measurement vector z\n",
    "z[0:2] are the measurements from the camera (px, py, orientation)\n",
    "z[3:4] are the measurements from the Thymio (forward speed v and angular speed omega)\n",
    "\n",
    "When Thymio position not found by camera -> z becomes 2x1 vector, with z[0:1] being the forward speed v and angular speed omega\n",
    "'''\n",
    "\n",
    "\n",
    "class KalmanFilter():\n",
    "    def __init__(self, dt, x_ini):\n",
    "        self.dt = dt\n",
    "\n",
    "        # Initial State Vector\n",
    "        self.x=np.matrix([[x_ini[0]], [x_ini[1]], [x_ini[2]], [x_ini[3]], [x_ini[4]]])\n",
    "    \n",
    "\n",
    "        # Initialize State Transition Matrix (Warning : changes with time -> updateFk())\n",
    "        self.Fk=np.eye(5)\n",
    "\n",
    "        # Initialize Measurement matrix H\n",
    "        # Used to convert the predicted state estimate into predicted sensor measurements at time k.\n",
    "        # In this case, H will be the identity matrix since the estimated state maps directly to state measurements data\n",
    "        # H has the same number of rows as sensor measurements and same number of columns as states.\n",
    "        self.H=np.eye(5)\n",
    "\n",
    "        \n",
    "        # State model noise covariance matrix Q\n",
    "        # When Q is large, the Kalman Filter tracks large changes in\n",
    "        # the sensor measurements more closely than for smaller Q.\n",
    "        # Q is a square matrix that has the same number of rows as states.\n",
    "        self.Q=np.diag([1, 0.1, 0.01, 1.0, 1.0]) \n",
    "        \n",
    "\n",
    "        # Sensor measurement noise covariance matrix R\n",
    "        # Has the same number of rows and columns as sensor measurements.\n",
    "        # If we are sure about the measurements, R will be near zero.\n",
    "        self.coord_var = 0.01\n",
    "        self.angle_var = 0.0001\n",
    "        self.speed_var = 6.0\n",
    "        self.omega_var = 0\n",
    "        \n",
    "        self.R=np.diag([self.coord_var, self.coord_var, self.angle_var, self.speed_var, self.omega_var])\n",
    "\n",
    "        self.P=np.eye(5)\n",
    "        \n",
    "    def updateFk(self):\n",
    "        '''\n",
    "        Function that updates the state transition matrix Fk\n",
    "        '''\n",
    "        \n",
    "        self.Fk=np.matrix([[1.0, 0, 0, self.dt*math.cos(self.x[2]), 0],\n",
    "                           [0, 1.0,  0, self.dt*math.sin(self.x[2]), 0],\n",
    "                           [0, 0, 1.0, 0, self.dt],\n",
    "                           [0, 0, 0, 1.0, 0],\n",
    "                           [0, 0, 0, 0, 1.0]])\n",
    "        self.Fk = self.Fk.astype(float)\n",
    "\n",
    "    def predict(self):\n",
    "        # Update Fk\n",
    "        self.updateFk()\n",
    "        # Predict the state estimate (A Priori) at time k based on the state estimate at time k-1\n",
    "        self.x=np.dot(self.Fk, self.x)\n",
    "        # Predict the state covariance estimate based on the previous covariance and some noise\n",
    "        self.P=np.dot(np.dot(self.Fk, self.P), self.Fk.T)+self.Q\n",
    "        return self.x\n",
    "\n",
    "    def update(self, z, CameraAccessible = True): # z[0:2] corrpesonds to measurement of camera, z[3:4] corresponds to measurements of wheels\n",
    "        \n",
    "        if CameraAccessible:\n",
    "            self.H=np.eye(5)\n",
    "            \n",
    "            self.R=np.diag([self.coord_var, self.coord_var, self.angle_var, self.speed_var, self.omega_var])\n",
    "        else: # CAUTION : IF CAMERAACCESSIBLE = FALSE, Z IS A 2x1 VECTOR (z[0:1] are now measrurements from wheels)\n",
    "            # Measurement matrix H (now only v and omega can be observed)\n",
    "            self.H=np.matrix([[0, 0, 0, 1, 0],\n",
    "                              [0, 0, 0, 0, 1]])\n",
    "            \n",
    "            self.R=np.diag([self.speed_var, self.omega_var])\n",
    "            \n",
    "            \n",
    "        # Compute Kalman gain\n",
    "        S=np.dot(self.H, np.dot(self.P, self.H.T))+self.R\n",
    "        inv_S = np.linalg.pinv(S.astype(float))\n",
    "        K=np.dot(np.dot(self.P, self.H.T),inv_S)\n",
    "\n",
    "        # Correction / innovation\n",
    "        # Calculate an updated state estimate (A Posteriori) for time k\n",
    "        self.x=self.x+np.dot(K, (z-np.dot(self.H, self.x)))\n",
    "        # Update the state covariance estimate for time k\n",
    "        I=np.eye(self.H.shape[1])\n",
    "        self.P=(I-(K*self.H))*self.P\n",
    "\n",
    "\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fc08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d25434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(pt1, pt2):\n",
    "    distance = ( (pt1[0]-pt2[0])**2 + (pt1[1]-pt2[1])**2 )**0.5\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd9c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thymio_position(img, img_output):\n",
    "    \n",
    "    '''\n",
    "    Function that outputs Thymio position, radius and orientation from camera frames using Aruco marker detection\n",
    "    Parts of code taken from https://mecaruco2.readthedocs.io/en/latest/notebooks_rst/Aruco/aruco_basics.html\n",
    "\n",
    "    Inputs: - img : image from camera in BGR format\n",
    "            - img_output : copy of image img on which will be drawn Thymio's contours\n",
    "\n",
    "    Output: - center : tuple (x,y) representing the center of the Thymio (in pixels)\n",
    "            - radius : radius of the Thymio (in pixels)\n",
    "            - angle : orientation of the Thymio (in radians)\n",
    "            - thymio_detected : boolean set to True if Thymio was detected, False if not\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    aruco_dict = aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "    parameters =  aruco.DetectorParameters_create()\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "    frame_markers = aruco.drawDetectedMarkers(img_output, corners, ids)\n",
    "    \n",
    "    \n",
    "    thymio_detected = False\n",
    "    center = (0,0)\n",
    "    radius = 0\n",
    "    angle = 0\n",
    "    \n",
    "    if np.all(ids != None):\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] == 0:\n",
    "                thymio_detected = True\n",
    "                c = corners[i][0]\n",
    "\n",
    "                top_center = (c[0:2, 0].mean(),c[0:2, 1].mean())\n",
    "                bottom_center = (c[2:4, 0].mean(), c[2:4, 1].mean())\n",
    "                left_center = (c[0:4:3, 0].mean(), c[0:4:3, 1].mean())\n",
    "                right_center = (c[1:3, 0].mean(), c[1:3, 1].mean())\n",
    "                points = np.array([ [c[2,0],c[2,1]], [c[3,0],c[3,1]], [left_center[0],left_center[1]], [right_center[0],right_center[1]] ])\n",
    "\n",
    "                square_center = (int(c[:, 0].mean()), int(c[:, 1].mean()))\n",
    "                radius = int(max( dist(square_center,c[0]), dist(square_center,c[1]), dist(square_center,c[2]), dist(square_center,c[3])))\n",
    "                angle = math.atan2(top_center[1]-bottom_center[1],top_center[0]-bottom_center[0])\n",
    "                \n",
    "                \n",
    "                center = (int(points[:, 0].mean()), int(points[:, 1].mean()))\n",
    "                cv2.arrowedLine(img_output, (center[0],center[1]), (int(top_center[0]),int(top_center[1])), (255,255,0), 10)\n",
    "                cv2.circle(img_output,square_center,radius,(255,0,0),10)\n",
    "\n",
    "                break\n",
    "\n",
    "        \n",
    "    return center, radius, angle, thymio_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c069c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1d540f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unchecked Raise(exc=Call(func=Name(id='IOError', ctx=Load()), args=[Constant(value='Cannot open webcam', kind=None)], keywords=[]), cause=None)\n",
      "fps: 30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "set_var() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rayendhahri\\Desktop\\mobile_robotics\\src\\TrackingTest.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         set_var(motor_right_target, \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     \u001b[39m# here global path planning\t\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     set_var(motor_left_target, \u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     set_var(motor_right_target, \u001b[39m100\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rayendhahri/Desktop/mobile_robotics/src/TrackingTest.ipynb#X16sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     wait \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \n",
      "\u001b[1;31mTypeError\u001b[0m: set_var() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing Kalman Filter\n",
    "'''\n",
    "\n",
    "global center, radius, angle, thymio_detected\n",
    "\n",
    "forward_speed = 0\n",
    "angular_speed = 0\n",
    "\n",
    "KF=KalmanFilter(0.033, [500, 300, math.pi/4, forward_speed, angular_speed])\n",
    "\n",
    "\n",
    "\n",
    "### INITIALIZE CAMERA\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "fps = int(cap.get(5))\n",
    "print(\"fps:\", fps)\n",
    "\n",
    "success, img = cap.read()\n",
    "imgResult = img.copy()\n",
    "    \n",
    "thymioLoc, thymioRadius, thymioAngle, thymioDetected = get_thymio_position(img, imgResult)\n",
    "\n",
    "\n",
    "path = [[thymioLoc[0],thymioLoc[1]],[thymioLoc[0]+300,thymioLoc[1]+300],[thymioLoc[0]+500,thymioLoc[1]-300]]\n",
    "\n",
    "### MAIN LOOP\n",
    "count = 0\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "path_step = 0\n",
    "    \n",
    "# running infinite while loop so that\n",
    "# program keep running until we close it\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgResult = img.copy()\n",
    "    \n",
    "    thymioLoc, thymioRadius, thymioAngle, thymioDetected = get_thymio_position(img, imgResult)\n",
    "    prox = get_var(\"prox.horizontal\")[0]\n",
    "    #print(prox)\n",
    "    if any([x>21000 and x < 31000 for x in prox]):\n",
    "            print(\"obstacle is very close\") \n",
    "            avoid = False\n",
    "            #prox =prox\n",
    "            var_prox= np.array(prox)\n",
    "            if (var_prox[:1].sum() > var_prox[3:4].sum()) and (var_prox[2] < 3000):\n",
    "                set_var(motor_left_target= 100)\n",
    "                set_var(motor_right_target= -100)\n",
    "                print(\"should turn left\")\n",
    "            elif var_prox[2] > 3000: \n",
    "                set_var(motor_left_target= 100)\n",
    "                set_var(motor_right_target= -100)\n",
    "                print(\"should turn left\")\n",
    "\n",
    "            else:\n",
    "                print(\"should turn right\")\n",
    "                set_var(motor_left_target= -100)\n",
    "                set_var(motor_right_target= 100)\n",
    "\n",
    "\n",
    "    elif any([x>3700 for x in prox]):\n",
    "        print(\"obstacle is close\")\n",
    "        # ON PLACE ROTATION\n",
    "        avoid = False\n",
    "        #prox =prox\n",
    "        var_prox= np.array(prox)\n",
    "        if (var_prox[:1].sum() > var_prox[3:4].sum()):\n",
    "            #node.send_set_variables(move(0, -100))\n",
    "            set_var(motor_left_target= 0)\n",
    "            set_var(motor_right_target= -100)\n",
    "            print(\"motor right\")\n",
    "        elif (var_prox[:1].sum() < var_prox[3:4].sum()):\n",
    "            set_var(motor_left_target= -100)\n",
    "            set_var(motor_right_target= 0)\n",
    "            print(\"motor left\")\n",
    "        else:\n",
    "            set_var(motor_left_target= -100)\n",
    "            set_var(motor_right_target= 0)\n",
    "\n",
    "    else:\n",
    "        # here global path planning\t\n",
    "        set_var(motor_left_target=100)\n",
    "        set_var(motor_right_target = 100)\n",
    "        wait = 1 \n",
    "        # set motors normally here\n",
    "        time.sleep(wait)\n",
    "        avoid = True\n",
    "    \n",
    "\n",
    "    # KALMAN -------------------------------------------------------------------\n",
    "    KF.predict()\n",
    "    if thymioDetected:\n",
    "        z = np.array([thymioLoc[0],thymioLoc[1],thymioAngle, forward_speed, angular_speed])\n",
    "        z = np.expand_dims(z, axis=-1)\n",
    "    else:\n",
    "        z = np.array([forward_speed, angular_speed]) \n",
    "        z = np.expand_dims(z, axis=-1)\n",
    "    KF.update(z,thymioDetected)\n",
    "    cv2.circle(imgResult, (int(KF.x[0]), int(KF.x[1])), 10, (255,0,255), 10)\n",
    "    # KALMAN ----------------------------------------------------------------------\n",
    "    count = count + 1\n",
    "    #print(count)\n",
    "    #print('Thymio center:',thymioLoc, '  Angle:',thymioAngle, '  Thymio Detected:' ,thymioDetected)\n",
    "    #print('Kalman center:',KF.x[0:2],'  Kalman angle:',KF.x[2], 'Kalman speed and omega', KF.x[3:5])\n",
    "    \n",
    "    #Path tracking ----------------------------------------------------------------\n",
    "    x = KF.x.item(0)\n",
    "    y = KF.x.item(1)\n",
    "    angle = KF.x.item(2)\n",
    "    \n",
    "    #if Point(x,y).distance(Point())\n",
    "    \n",
    "    traj_seg = Segment(Point(*tuple(path[path_step])),Point(*tuple(path[path_step+1])))\n",
    "    traj_ray = Ray(Point(*tuple(path[path_step+1])),Point(*tuple(path[path_step])))\n",
    "    robot_dot = Point(x,y)\n",
    "    robot_ray = Ray(Point(*tuple(path[path_step+1])),robot_dot)\n",
    "    vert_ray = Ray(Point(*tuple(path[path_step])),angle=0)\n",
    "    origin = Point(0,0)\n",
    "    error = traj_seg.distance(robot_dot)\n",
    "    imgResult = cv2.putText(imgResult, \"Error: {0}\".format(int(error)), (200,200), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    ref_angle = np.arctan((path[path_step][1]-path[path_step+1][1])/(path[path_step][0]-path[path_step+1][0])) #vert_ray.angle_between(traj_ray)\n",
    "    if robot_ray.closing_angle(traj_ray) < 0:\n",
    "        error = -error\n",
    "\n",
    "    \n",
    "    kp = 0.02\n",
    "    correction = kp*error\n",
    "    correction = max(-np.pi/2, correction)\n",
    "    correction = min(np.pi/2, correction)\n",
    "    target_angle = ref_angle + correction\n",
    "    \n",
    "    speed_offset = 50\n",
    "    \n",
    "    kp_angle = 100\n",
    "    angle_error = target_angle-angle\n",
    "    speed_diff = kp_angle*angle_error\n",
    "    set_var(motor_left_target = int(speed_offset + speed_diff))\n",
    "    set_var(motor_right_target = int(speed_offset - speed_diff))\n",
    "\n",
    "    \n",
    "    imgResult = cv2.putText(imgResult, \"Angle: {0}\".format(int(angle*180/np.pi)), (200,300), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"ref angle: {0}\".format(int(ref_angle*180/np.pi)), (200,400), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"correction: {0}\".format(int(correction*180/np.pi)), (200,500), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"target_angle: {0}\".format(int(target_angle*180/np.pi)), (200,600), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"speed_diff: {0}\".format(int(speed_diff)), (200,700), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"angle_error: {0}\".format(int(angle_error*180/np.pi)), (200,800), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "    imgResult = cv2.putText(imgResult, \"angle traj: {0}\".format(int(robot_ray.closing_angle(traj_ray)*180/np.pi)), (200,900), cv2.FONT_HERSHEY_SIMPLEX ,2, (0,0,255),2, cv2.LINE_AA)\n",
    "\n",
    "    # displaying output on Screen\n",
    "    imgResult = cv2.line(imgResult,tuple(path[0]),tuple(path[1]),(255,255,255),1)\n",
    "    imgResult = cv2.line(imgResult,tuple(path[1]),tuple(path[2]),(255,255,255),1)\n",
    "    cv2.imshow(\"Result\", imgResult)\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        cv2.destroyWindow(\"Result\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349851e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_var(motor_left_target = 0)\n",
    "set_var(motor_right_target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7946f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d1a14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('machine')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab7da87cccf87de40107b9980703dc70daf91aebb64c128398fb393961176ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
